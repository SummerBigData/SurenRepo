Using TensorFlow backend.
/users/PAS1383/osu10171/.conda/envs/local/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
You have chosen: Namespace(bsize=128, epo=50, f1=16875, f2=512, f3=2, m=1604)
 
x and y (10028, 16875) (10028,)
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
encoder_input (InputLayer)       (None, 16875)         0                                            
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 512)           8640512     encoder_input[0][0]              
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 512)           262656      dense_1[0][0]                    
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 512)           262656      dense_2[0][0]                    
____________________________________________________________________________________________________
z_mean (Dense)                   (None, 2)             1026        dense_3[0][0]                    
____________________________________________________________________________________________________
z_log_var (Dense)                (None, 2)             1026        dense_3[0][0]                    
____________________________________________________________________________________________________
z (Lambda)                       (None, 2)             0           z_mean[0][0]                     
                                                                   z_log_var[0][0]                  
====================================================================================================
Total params: 9,167,876
Trainable params: 9,167,876
Non-trainable params: 0
____________________________________________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
z_sampling (InputLayer)      (None, 2)                 0         
_________________________________________________________________
dense_4 (Dense)              (None, 512)               1536      
_________________________________________________________________
dense_5 (Dense)              (None, 512)               262656    
_________________________________________________________________
dense_6 (Dense)              (None, 512)               262656    
_________________________________________________________________
dense_7 (Dense)              (None, 16875)             8656875   
=================================================================
Total params: 9,183,723
Trainable params: 9,183,723
Non-trainable params: 0
_________________________________________________________________
print 2 (?,) (?,)
iceVAE.py:181: UserWarning: Output "decoder" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to "decoder" during training.
  vae.compile(optimizer='adam', loss=None)
Train on 10028 samples, validate on 10028 samples
Epoch 1/50
2018-07-19 13:21:12.461466: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-19 13:21:12.461976: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
124s - loss: 828.0136 - val_loss: 13.0815
Epoch 2/50
123s - loss: 2.5887 - val_loss: 1.6587
Epoch 3/50
122s - loss: 15.8353 - val_loss: 4.4696
Epoch 4/50
123s - loss: 2.1019 - val_loss: 1.5592
Epoch 5/50
123s - loss: 1.5485 - val_loss: 2.1683
Epoch 6/50
123s - loss: 15.9895 - val_loss: 1.9248
Epoch 7/50
123s - loss: 1.5651 - val_loss: 1.5392
Epoch 8/50
123s - loss: 1.5267 - val_loss: 1.5375
Epoch 9/50
123s - loss: 1.5430 - val_loss: 1.5387
Epoch 10/50
